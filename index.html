<!doctype html>
<html lang="en" dir="ltr" class="mdx-wrapper mdx-page plugin-pages plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">Silviu Vlad Oprea</title><meta data-rh="true" property="og:title" content="Silviu Vlad Oprea"><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://silviu-oprea.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://silviu-oprea.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://silviu-oprea.github.io/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" name="description" content="&lt;img"><meta data-rh="true" property="og:description" content="&lt;img"><link data-rh="true" rel="icon" href="/img/svo.svg"><link data-rh="true" rel="canonical" href="https://silviu-oprea.github.io/"><link data-rh="true" rel="alternate" href="https://silviu-oprea.github.io/" hreflang="en"><link data-rh="true" rel="alternate" href="https://silviu-oprea.github.io/" hreflang="x-default"><script data-rh="true">function maybeInsertBanner(){window.__DOCUSAURUS_INSERT_BASEURL_BANNER&&insertBanner()}function insertBanner(){var n=document.getElementById("__docusaurus-base-url-issue-banner-container");if(n){n.innerHTML='\n<div id="__docusaurus-base-url-issue-banner" style="border: thick solid red; background-color: rgb(255, 230, 179); margin: 20px; padding: 20px; font-size: 20px;">\n   <p style="font-weight: bold; font-size: 30px;">Your Docusaurus site did not load properly.</p>\n   <p>A very common reason is a wrong site <a href="https://docusaurus.io/docs/docusaurus.config.js/#baseUrl" style="font-weight: bold;">baseUrl configuration</a>.</p>\n   <p>Current configured baseUrl = <span style="font-weight: bold; color: red;">/</span>  (default value)</p>\n   <p>We suggest trying baseUrl = <span id="__docusaurus-base-url-issue-banner-suggestion-container" style="font-weight: bold; color: green;"></span></p>\n</div>\n';var e=document.getElementById("__docusaurus-base-url-issue-banner-suggestion-container"),s=window.location.pathname,r="/"===s.substr(-1)?s:s+"/";e.innerHTML=r}}window.__DOCUSAURUS_INSERT_BASEURL_BANNER=!0,document.addEventListener("DOMContentLoaded",maybeInsertBanner)</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Silviu Vlad Oprea RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Silviu Vlad Oprea Atom Feed"><link rel="stylesheet" href="/assets/css/styles.78e3864f.css">
<link rel="preload" href="/assets/js/runtime~main.cf15a1a1.js" as="script">
<link rel="preload" href="/assets/js/main.2b128fc2.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div id="__docusaurus-base-url-issue-banner-container"></div><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">Silviu Vlad Oprea</b></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li></ul></div></div><div class="navbar__items navbar__items--right"><a href="https://scholar.google.com/citations?user=IOVYUDwAAAAJ" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar__icon navbar__google_scholar"></a><a href="https://www.semanticscholar.org/author/2066295029" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar__icon navbar__semantic_scholar"></a><a href="https://orcid.org/0009-0006-7038-5489" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar__icon navbar__orcid"></a><a href="https://www.webofscience.com/wos/author/record/JJE-8903-2023" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar__icon navbar__clarivate"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><main class="container container--fluid margin-vert--lg"><div class="row mdxPageWrapper_j9I6"><div class="col col--8"><article><div class="image-and-text-box"><img loading="lazy" src="/assets/images/photo-b39a2a2486ccd616b543648510943252.jpeg" width="180" class="z-depth-1 img_ev3q"><div><p><u>Applied Scientist at Amazon. PhD from the University of Edinburgh.</u></p><p>I am interested in building computational agents that process natural language and react in a manner that brings value to our lives.</p><p>Towards this vision, I am considering problems that arise in generative artificial intelligence, in particular as supported by large language models (LLMs), including knowledge grounding and in-context learning. I have also worked on problems in Computational Social Science, Figurative Language Comprehension, Machine Translation, and Computer Vision.</p><p><code>silviu dot vlad dot oprea at gmail dot com</code></p><p><a href="https://scholar.google.com/citations?user=IOVYUDwAAAAJ" target="_blank" rel="noopener noreferrer" class="image-and-text-box-icon navbar__icon navbar__google_scholar"></a><a href="https://www.semanticscholar.org/author/2066295029" target="_blank" rel="noopener noreferrer" class="image-and-text-box-icon navbar__icon navbar__semantic_scholar"></a><a href="https://orcid.org/0009-0006-7038-5489" target="_blank" rel="noopener noreferrer" class="image-and-text-box-icon navbar__icon navbar__orcid"></a><a href="https://www.webofscience.com/wos/author/record/JJE-8903-2023" target="_blank" rel="noopener noreferrer" class="image-and-text-box-icon navbar__icon navbar__clarivate"></a></p></div></div><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="news">News<a href="#news" class="hash-link" aria-label="Direct link to News" title="Direct link to News">‚Äã</a></h2><ul><li><b>3 March 2023</b>: <!-- -->I passed my PhD viva with no reviewable corrections ü•≥! Thanks be to God üôèüèª; to my supervisors <a target="_blank" rel="noopener noreferrer" href="https://homepages.inf.ed.ac.uk/wmagdy/">Walid Magdy</a>, <a target="_blank" rel="noopener noreferrer" href="https://homepages.inf.ed.ac.uk/bonnie/">Bonnie Webber</a>, and <a target="_blank" rel="noopener noreferrer" href="https://mariawolters.net/">Maria Wolters</a>; and to my examiners <a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/view/alexandra-birch/">Alexandra Birch-Mayne</a> and <a target="_blank" rel="noopener noreferrer" href="https://web.eecs.umich.edu/~mihalcea/">Rada Mihalcea</a>. Check out my thesis, <a target="_blank" rel="noopener noreferrer" href="https://era.ed.ac.uk/handle/1842/40531">Computational Sarcasm Detection and Understanding in Online Communication</a>.</li><li><b>4 April 2022</b>: <!-- -->Our patent, <a target="_blank" rel="noopener noreferrer" href="https://worldwide.espacenet.com/patent/search/family/072709373/publication/WO2022069030A1?q=WO2022069030A1&amp;queryLang=en%3Ade%3Afr">Processing communications in a computing arrangement for semantic understanding and interpretation of code-switching</a>, by Sourav Dutta, <u>Silviu Vlad Oprea</u>, Salama Hitham, and Hu Peng, was published.</li><li><b>30 June 2021</b>: <!-- -->The flood segmentation model that we built at <a target="_blank" rel="noopener noreferrer" href="https://fdleurope.org">Frontier Development Lab</a> has now been deployed by SpaceX on an actual satellite üõ∞. Along the way, we collaborated with the European Space Agency and UNICEF. Our work was covered by <a target="_blank" rel="noopener noreferrer" href="https://www.ox.ac.uk/news/2021-06-29-artificial-intelligence-pioneered-oxford-detect-floods-launches-space">this</a> post from the University of Oxford; and by several media outlets: <a target="_blank" rel="noopener noreferrer" href="https://watchers.news/2021/07/11/worldfloods-ai-pioneered-at-oxford-for-global-flood-mapping-launches-into-space/">1</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.innovationnewsnetwork.com/historic-breakthroughs-in-flood-mapping-from-space/24369/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=historic-breakthroughs-in-flood-mapping-from-space)">2</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.homelandsecuritynewswire.com/dr20210712-detecting-floods-from-space-using-artificial-intelligence">3</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.cas.cn/kj/202107/t20210722_4799503.shtml">4</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.kepuchina.cn/more/202107/t20210722_3010644.shtml">5</a>. Check out our <a target="_blank" rel="noopener noreferrer" href="/publications/#Mateo-Garcia2021">Nature (Scientific Reports) paper</a> and the <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=sSiuW1HcGjA">video of the rocket launch</a> üöÄ</li></ul><p>See more news <a href="/news">here</a>.</p><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="education">Education<a href="#education" class="hash-link" aria-label="Direct link to Education" title="Direct link to Education">‚Äã</a></h2><style data-emotion="css 1nk1ud8">.css-1nk1ud8{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding:6px 16px;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}.css-1nk1ud8 .MuiTimelineItem-root:before{-webkit-flex:0;-ms-flex:0;flex:0;padding:0px;}.css-1nk1ud8 .MuiTimelineContent-root{margin-top:.7em;}</style><ul class="MuiTimeline-root MuiTimeline-positionRight css-1nk1ud8"><style data-emotion="css 1rcbby2">.css-1rcbby2{list-style:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;position:relative;min-height:70px;}.css-1rcbby2:before{content:"";-webkit-flex:1;-ms-flex:1;flex:1;padding:6px 16px;}</style><li class="MuiTimelineItem-root MuiTimelineItem-positionRight MuiTimelineItem-missingOppositeContent css-1rcbby2"><style data-emotion="css 11tgw8h">.css-11tgw8h{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:0;-ms-flex:0;flex:0;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><div class="MuiTimelineSeparator-root css-11tgw8h"><style data-emotion="css 1mfc72q">.css-1mfc72q{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-self:baseline;-ms-flex-item-align:baseline;align-self:baseline;border-style:solid;border-width:2px;padding:4px;border-radius:50%;box-shadow:0px 2px 1px -1px rgba(0,0,0,0.2),0px 1px 1px 0px rgba(0,0,0,0.14),0px 1px 3px 0px rgba(0,0,0,0.12);margin:11.5px 0;border-color:transparent;color:#fafafa;background-color:#bdbdbd;background-color:var(--ifm-link-color);}</style><span class="MuiTimelineDot-root MuiTimelineDot-filled MuiTimelineDot-filledGrey css-1mfc72q"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="graduation-cap" class="svg-inline--fa fa-graduation-cap fa-lg" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M320 32c-8.1 0-16.1 1.4-23.7 4.1L15.8 137.4C6.3 140.9 0 149.9 0 160s6.3 19.1 15.8 22.6l57.9 20.9C57.3 229.3 48 259.8 48 291.9v28.1c0 28.4-10.8 57.7-22.3 80.8c-6.5 13-13.9 25.8-22.5 37.6C0 442.7-.9 448.3 .9 453.4s6 8.9 11.2 10.2l64 16c4.2 1.1 8.7 .3 12.4-2s6.3-6.1 7.1-10.4c8.6-42.8 4.3-81.2-2.1-108.7C90.3 344.3 86 329.8 80 316.5V291.9c0-30.2 10.2-58.7 27.9-81.5c12.9-15.5 29.6-28 49.2-35.7l157-61.7c8.2-3.2 17.5 .8 20.7 9s-.8 17.5-9 20.7l-157 61.7c-12.4 4.9-23.3 12.4-32.2 21.6l159.6 57.6c7.6 2.7 15.6 4.1 23.7 4.1s16.1-1.4 23.7-4.1L624.2 182.6c9.5-3.4 15.8-12.5 15.8-22.6s-6.3-19.1-15.8-22.6L343.7 36.1C336.1 33.4 328.1 32 320 32zM128 408c0 35.3 86 72 192 72s192-36.7 192-72L496.7 262.6 354.5 314c-11.1 4-22.8 6-34.5 6s-23.5-2-34.5-6L143.3 262.6 128 408z"></path></svg></span><style data-emotion="css t0sc32">.css-t0sc32{width:2px;background-color:#bdbdbd;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;background-color:var(--ifm-link-color);}</style><span class="MuiTimelineConnector-root css-t0sc32"></span></div><style data-emotion="css cjv0ik">.css-cjv0ik{-webkit-flex:1;-ms-flex:1;flex:1;padding:6px 16px;text-align:left;}</style><style data-emotion="css 7p547w">.css-7p547w{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:1rem;line-height:1.5;letter-spacing:0.00938em;-webkit-flex:1;-ms-flex:1;flex:1;padding:6px 16px;text-align:left;}</style><div class="MuiTypography-root MuiTypography-body1 MuiTimelineContent-root MuiTimelineContent-positionRight css-7p547w"><p style="color:var(--ifm-color-primary)">2018 - 2023<!-- -->: <!-- -->PhD in Data Science<!-- --> at <!-- -->the University of Edinburgh</p><p></p><p>Check out my thesis, <a target="_blank" rel="noopener noreferrer" href="https://era.ed.ac.uk/handle/1842/40531">Computational Sarcasm Detection and Understanding in Online Communication</a>.</p><p>In summary, I used computational methods to detect and understand the phenomenon of sarcasm, as it is manifested in online textual communication, together with my supervisors, <a target="_blank" rel="noopener noreferrer" href="https://homepages.inf.ed.ac.uk/wmagdy/">Walid Magdy</a>, <a target="_blank" rel="noopener noreferrer" href="https://homepages.inf.ed.ac.uk/bonnie/">Bonnie Webber</a>, and <a target="_blank" rel="noopener noreferrer" href="https://mariawolters.net/">Maria Wolters</a>.</p><p>More specifically, I built a dataset of texts annotated for sarcasm (<a target="_blank" rel="noopener noreferrer" href="https://aclanthology.org/2020.acl-main.118.pdf">ACL 2020 paper</a>), introduced sarcasm detection models (<a target="_blank" rel="noopener noreferrer" href="https://aclanthology.org/P19-1275.pdf">ACL 2019 paper</a>), and also organised a competition encouraging the community to build such models (<a target="_blank" rel="noopener noreferrer" href="https://aclanthology.org/2022.semeval-1.111.pdf">SemEval 2022 paper</a>). I showed that people of similar socio-demographic backgrounds understand each other&#x27;s sarcasm more often than people of dissimilar backgrounds (<a target="_blank" rel="noopener noreferrer" href="https://doi.org/10.1145/3392834">CSCW 2022 paper</a>). Finally, I built a sarcastic chatbot (<a target="_blank" rel="noopener noreferrer" href="https://aclanthology.org/2021.emnlp-demo.38.pdf">EMNLP 2021 demo</a>), and investigated when it is appropriate for chatbots to be sarcastic, and how they should formulate their utterances (<a target="_blank" rel="noopener noreferrer" href="https://aclanthology.org/2022.acl-long.530.pdf">ACL 2022 paper</a>).</p><p>Along the way, I had fun as an intern at Frontier Development Lab in 2019, at Huawei in 2020, and at Amazon Alexa AI in 2021. See below, in the <i>Work</i> section.</p><p></p></div></li><li class="MuiTimelineItem-root MuiTimelineItem-positionRight MuiTimelineItem-missingOppositeContent css-1rcbby2"><div class="MuiTimelineSeparator-root css-11tgw8h"><span class="MuiTimelineDot-root MuiTimelineDot-filled MuiTimelineDot-filledGrey css-1mfc72q"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="graduation-cap" class="svg-inline--fa fa-graduation-cap fa-lg" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M320 32c-8.1 0-16.1 1.4-23.7 4.1L15.8 137.4C6.3 140.9 0 149.9 0 160s6.3 19.1 15.8 22.6l57.9 20.9C57.3 229.3 48 259.8 48 291.9v28.1c0 28.4-10.8 57.7-22.3 80.8c-6.5 13-13.9 25.8-22.5 37.6C0 442.7-.9 448.3 .9 453.4s6 8.9 11.2 10.2l64 16c4.2 1.1 8.7 .3 12.4-2s6.3-6.1 7.1-10.4c8.6-42.8 4.3-81.2-2.1-108.7C90.3 344.3 86 329.8 80 316.5V291.9c0-30.2 10.2-58.7 27.9-81.5c12.9-15.5 29.6-28 49.2-35.7l157-61.7c8.2-3.2 17.5 .8 20.7 9s-.8 17.5-9 20.7l-157 61.7c-12.4 4.9-23.3 12.4-32.2 21.6l159.6 57.6c7.6 2.7 15.6 4.1 23.7 4.1s16.1-1.4 23.7-4.1L624.2 182.6c9.5-3.4 15.8-12.5 15.8-22.6s-6.3-19.1-15.8-22.6L343.7 36.1C336.1 33.4 328.1 32 320 32zM128 408c0 35.3 86 72 192 72s192-36.7 192-72L496.7 262.6 354.5 314c-11.1 4-22.8 6-34.5 6s-23.5-2-34.5-6L143.3 262.6 128 408z"></path></svg></span><span class="MuiTimelineConnector-root css-t0sc32"></span></div><div class="MuiTypography-root MuiTypography-body1 MuiTimelineContent-root MuiTimelineContent-positionRight css-7p547w"><p style="color:var(--ifm-color-primary)">2017 - 2018<!-- -->: <!-- -->MRes in Data Science<!-- --> at <!-- -->the University of Edinburgh</p><p>I used computational methods to detect the presence of sarcasm in tweets, together with my supervisor, <a target="_blank" rel="noopener noreferrer" href="https://homepages.inf.ed.ac.uk/wmagdy/">Walid Magdy</a>.</p></div></li><li class="MuiTimelineItem-root MuiTimelineItem-positionRight MuiTimelineItem-missingOppositeContent css-1rcbby2"><div class="MuiTimelineSeparator-root css-11tgw8h"><span class="MuiTimelineDot-root MuiTimelineDot-filled MuiTimelineDot-filledGrey css-1mfc72q"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="graduation-cap" class="svg-inline--fa fa-graduation-cap fa-lg" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M320 32c-8.1 0-16.1 1.4-23.7 4.1L15.8 137.4C6.3 140.9 0 149.9 0 160s6.3 19.1 15.8 22.6l57.9 20.9C57.3 229.3 48 259.8 48 291.9v28.1c0 28.4-10.8 57.7-22.3 80.8c-6.5 13-13.9 25.8-22.5 37.6C0 442.7-.9 448.3 .9 453.4s6 8.9 11.2 10.2l64 16c4.2 1.1 8.7 .3 12.4-2s6.3-6.1 7.1-10.4c8.6-42.8 4.3-81.2-2.1-108.7C90.3 344.3 86 329.8 80 316.5V291.9c0-30.2 10.2-58.7 27.9-81.5c12.9-15.5 29.6-28 49.2-35.7l157-61.7c8.2-3.2 17.5 .8 20.7 9s-.8 17.5-9 20.7l-157 61.7c-12.4 4.9-23.3 12.4-32.2 21.6l159.6 57.6c7.6 2.7 15.6 4.1 23.7 4.1s16.1-1.4 23.7-4.1L624.2 182.6c9.5-3.4 15.8-12.5 15.8-22.6s-6.3-19.1-15.8-22.6L343.7 36.1C336.1 33.4 328.1 32 320 32zM128 408c0 35.3 86 72 192 72s192-36.7 192-72L496.7 262.6 354.5 314c-11.1 4-22.8 6-34.5 6s-23.5-2-34.5-6L143.3 262.6 128 408z"></path></svg></span><span class="MuiTimelineConnector-root css-t0sc32"></span></div><div class="MuiTypography-root MuiTypography-body1 MuiTimelineContent-root MuiTimelineContent-positionRight css-7p547w"><p style="color:var(--ifm-color-primary)">2012 - 2013<!-- -->: <!-- -->MSc in Computer Science<!-- --> at <!-- -->the University of Oxford</p><p>I worked with <a target="_blank" rel="noopener noreferrer" href="https://scholar.google.co.uk/citations?user=eJwbbXEAAAAJ">Phil Blunsom</a> on building character-level language models for the Romanian language using recurrent neural networks.</p></div></li><li class="MuiTimelineItem-root MuiTimelineItem-positionRight MuiTimelineItem-missingOppositeContent css-1rcbby2"><div class="MuiTimelineSeparator-root css-11tgw8h"><span class="MuiTimelineDot-root MuiTimelineDot-filled MuiTimelineDot-filledGrey css-1mfc72q"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="graduation-cap" class="svg-inline--fa fa-graduation-cap fa-lg" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M320 32c-8.1 0-16.1 1.4-23.7 4.1L15.8 137.4C6.3 140.9 0 149.9 0 160s6.3 19.1 15.8 22.6l57.9 20.9C57.3 229.3 48 259.8 48 291.9v28.1c0 28.4-10.8 57.7-22.3 80.8c-6.5 13-13.9 25.8-22.5 37.6C0 442.7-.9 448.3 .9 453.4s6 8.9 11.2 10.2l64 16c4.2 1.1 8.7 .3 12.4-2s6.3-6.1 7.1-10.4c8.6-42.8 4.3-81.2-2.1-108.7C90.3 344.3 86 329.8 80 316.5V291.9c0-30.2 10.2-58.7 27.9-81.5c12.9-15.5 29.6-28 49.2-35.7l157-61.7c8.2-3.2 17.5 .8 20.7 9s-.8 17.5-9 20.7l-157 61.7c-12.4 4.9-23.3 12.4-32.2 21.6l159.6 57.6c7.6 2.7 15.6 4.1 23.7 4.1s16.1-1.4 23.7-4.1L624.2 182.6c9.5-3.4 15.8-12.5 15.8-22.6s-6.3-19.1-15.8-22.6L343.7 36.1C336.1 33.4 328.1 32 320 32zM128 408c0 35.3 86 72 192 72s192-36.7 192-72L496.7 262.6 354.5 314c-11.1 4-22.8 6-34.5 6s-23.5-2-34.5-6L143.3 262.6 128 408z"></path></svg></span><span class="MuiTimelineConnector-root css-t0sc32"></span></div><div class="MuiTypography-root MuiTypography-body1 MuiTimelineContent-root MuiTimelineContent-positionRight css-7p547w"><p style="color:var(--ifm-color-primary)">2009 - 2012<!-- -->: <!-- -->BSc in Computer Science<!-- --> at <!-- -->Jacobs University Bremen</p><p>This is where my interest in natural language processing was triggered, working with <a target="_blank" rel="noopener noreferrer" href="https://kwarc.info/people/mkohlhase/">Michael Kohlhase</a>.</p></div></li></ul><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="work">Work<a href="#work" class="hash-link" aria-label="Direct link to Work" title="Direct link to Work">‚Äã</a></h2><style data-emotion="css 1nk1ud8">.css-1nk1ud8{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding:6px 16px;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}.css-1nk1ud8 .MuiTimelineItem-root:before{-webkit-flex:0;-ms-flex:0;flex:0;padding:0px;}.css-1nk1ud8 .MuiTimelineContent-root{margin-top:.7em;}</style><ul class="MuiTimeline-root MuiTimeline-positionRight css-1nk1ud8"><style data-emotion="css 1rcbby2">.css-1rcbby2{list-style:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;position:relative;min-height:70px;}.css-1rcbby2:before{content:"";-webkit-flex:1;-ms-flex:1;flex:1;padding:6px 16px;}</style><li class="MuiTimelineItem-root MuiTimelineItem-positionRight MuiTimelineItem-missingOppositeContent css-1rcbby2"><style data-emotion="css 11tgw8h">.css-11tgw8h{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:0;-ms-flex:0;flex:0;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><div class="MuiTimelineSeparator-root css-11tgw8h"><style data-emotion="css 1mfc72q">.css-1mfc72q{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-self:baseline;-ms-flex-item-align:baseline;align-self:baseline;border-style:solid;border-width:2px;padding:4px;border-radius:50%;box-shadow:0px 2px 1px -1px rgba(0,0,0,0.2),0px 1px 1px 0px rgba(0,0,0,0.14),0px 1px 3px 0px rgba(0,0,0,0.12);margin:11.5px 0;border-color:transparent;color:#fafafa;background-color:#bdbdbd;background-color:var(--ifm-link-color);}</style><span class="MuiTimelineDot-root MuiTimelineDot-filled MuiTimelineDot-filledGrey css-1mfc72q"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="laptop-code" class="svg-inline--fa fa-laptop-code fa-lg" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M64 96c0-35.3 28.7-64 64-64H512c35.3 0 64 28.7 64 64V352H512V96H128V352H64V96zM0 403.2C0 392.6 8.6 384 19.2 384H620.8c10.6 0 19.2 8.6 19.2 19.2c0 42.4-34.4 76.8-76.8 76.8H76.8C34.4 480 0 445.6 0 403.2zM281 209l-31 31 31 31c9.4 9.4 9.4 24.6 0 33.9s-24.6 9.4-33.9 0l-48-48c-9.4-9.4-9.4-24.6 0-33.9l48-48c9.4-9.4 24.6-9.4 33.9 0s9.4 24.6 0 33.9zM393 175l48 48c9.4 9.4 9.4 24.6 0 33.9l-48 48c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l31-31-31-31c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0z"></path></svg></span><style data-emotion="css t0sc32">.css-t0sc32{width:2px;background-color:#bdbdbd;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;background-color:var(--ifm-link-color);}</style><span class="MuiTimelineConnector-root css-t0sc32"></span></div><style data-emotion="css cjv0ik">.css-cjv0ik{-webkit-flex:1;-ms-flex:1;flex:1;padding:6px 16px;text-align:left;}</style><style data-emotion="css 7p547w">.css-7p547w{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:1rem;line-height:1.5;letter-spacing:0.00938em;-webkit-flex:1;-ms-flex:1;flex:1;padding:6px 16px;text-align:left;}</style><div class="MuiTypography-root MuiTypography-body1 MuiTimelineContent-root MuiTimelineContent-positionRight css-7p547w"><p style="color:var(--ifm-color-primary)">2022 - present<!-- -->: <!-- -->Applied Scientist<!-- --> at <!-- -->Amazon Alexa AI</p><p>I am working on improving the ability of large language models (LLMs) to generate more intuitive, personalised, and context-sensitive responses, and to interact with external systems, with the purpose of providing Alexa customers with a more delightful experience.</p></div></li><li class="MuiTimelineItem-root MuiTimelineItem-positionRight MuiTimelineItem-missingOppositeContent css-1rcbby2"><div class="MuiTimelineSeparator-root css-11tgw8h"><span class="MuiTimelineDot-root MuiTimelineDot-filled MuiTimelineDot-filledGrey css-1mfc72q"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="laptop-code" class="svg-inline--fa fa-laptop-code fa-lg" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M64 96c0-35.3 28.7-64 64-64H512c35.3 0 64 28.7 64 64V352H512V96H128V352H64V96zM0 403.2C0 392.6 8.6 384 19.2 384H620.8c10.6 0 19.2 8.6 19.2 19.2c0 42.4-34.4 76.8-76.8 76.8H76.8C34.4 480 0 445.6 0 403.2zM281 209l-31 31 31 31c9.4 9.4 9.4 24.6 0 33.9s-24.6 9.4-33.9 0l-48-48c-9.4-9.4-9.4-24.6 0-33.9l48-48c9.4-9.4 24.6-9.4 33.9 0s9.4 24.6 0 33.9zM393 175l48 48c9.4 9.4 9.4 24.6 0 33.9l-48 48c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l31-31-31-31c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0z"></path></svg></span><span class="MuiTimelineConnector-root css-t0sc32"></span></div><div class="MuiTypography-root MuiTypography-body1 MuiTimelineContent-root MuiTimelineContent-positionRight css-7p547w"><p style="color:var(--ifm-color-primary)">2021<!-- -->: <!-- -->Applied Scientist (Intern)<!-- --> at <!-- -->Amazon Alexa AI</p><p>At Amazon, I worked with Elisabeth Kwan, <a target="_blank" rel="noopener noreferrer" href="https://www.microsoft.com/en-us/research/people/mollyxia/">Molly Xia</a>, <a target="_blank" rel="noopener noreferrer" href="https://scholar.google.com/citations?user=oZORQtwAAAAJ&amp;hl=en">Christos Christodoulopoulos</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.amazon.science/author/dave-palfrey">Dave Palfrey</a>, and Stephen Teskey on language generation using language models. More details coming soon, a paper is in the baking üë®üèª‚Äçüç≥</p></div></li><li class="MuiTimelineItem-root MuiTimelineItem-positionRight MuiTimelineItem-missingOppositeContent css-1rcbby2"><div class="MuiTimelineSeparator-root css-11tgw8h"><span class="MuiTimelineDot-root MuiTimelineDot-filled MuiTimelineDot-filledGrey css-1mfc72q"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="laptop-code" class="svg-inline--fa fa-laptop-code fa-lg" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M64 96c0-35.3 28.7-64 64-64H512c35.3 0 64 28.7 64 64V352H512V96H128V352H64V96zM0 403.2C0 392.6 8.6 384 19.2 384H620.8c10.6 0 19.2 8.6 19.2 19.2c0 42.4-34.4 76.8-76.8 76.8H76.8C34.4 480 0 445.6 0 403.2zM281 209l-31 31 31 31c9.4 9.4 9.4 24.6 0 33.9s-24.6 9.4-33.9 0l-48-48c-9.4-9.4-9.4-24.6 0-33.9l48-48c9.4-9.4 24.6-9.4 33.9 0s9.4 24.6 0 33.9zM393 175l48 48c9.4 9.4 9.4 24.6 0 33.9l-48 48c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l31-31-31-31c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0z"></path></svg></span><span class="MuiTimelineConnector-root css-t0sc32"></span></div><div class="MuiTypography-root MuiTypography-body1 MuiTimelineContent-root MuiTimelineContent-positionRight css-7p547w"><p style="color:var(--ifm-color-primary)">2020<!-- -->: <!-- -->Research Scientist (Intern)<!-- --> at <!-- -->Huawei</p><p>At Huawei, I worked with <a target="_blank" rel="noopener noreferrer" href="https://scholar.google.co.uk/citations?user=804VsL8AAAAJ&amp;hl=en">Haytham Assem</a> and <a target="_blank" rel="noopener noreferrer" href="https://scholar.google.com/citations?user=9y1l5IoAAAAJ&amp;hl=en">Sourav Dutta</a> on learning transformations between monolingual word embedding spaces, to enable unsupervised translation and transfer learning to low-resource languages. Check out our <a target="_blank" rel="noopener noreferrer" href="https://aclanthology.org/2022.coling-1.92/">COLING 2022 paper</a> based on this work.</p></div></li><li class="MuiTimelineItem-root MuiTimelineItem-positionRight MuiTimelineItem-missingOppositeContent css-1rcbby2"><div class="MuiTimelineSeparator-root css-11tgw8h"><span class="MuiTimelineDot-root MuiTimelineDot-filled MuiTimelineDot-filledGrey css-1mfc72q"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="laptop-code" class="svg-inline--fa fa-laptop-code fa-lg" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M64 96c0-35.3 28.7-64 64-64H512c35.3 0 64 28.7 64 64V352H512V96H128V352H64V96zM0 403.2C0 392.6 8.6 384 19.2 384H620.8c10.6 0 19.2 8.6 19.2 19.2c0 42.4-34.4 76.8-76.8 76.8H76.8C34.4 480 0 445.6 0 403.2zM281 209l-31 31 31 31c9.4 9.4 9.4 24.6 0 33.9s-24.6 9.4-33.9 0l-48-48c-9.4-9.4-9.4-24.6 0-33.9l48-48c9.4-9.4 24.6-9.4 33.9 0s9.4 24.6 0 33.9zM393 175l48 48c9.4 9.4 9.4 24.6 0 33.9l-48 48c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l31-31-31-31c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0z"></path></svg></span><span class="MuiTimelineConnector-root css-t0sc32"></span></div><div class="MuiTypography-root MuiTypography-body1 MuiTimelineContent-root MuiTimelineContent-positionRight css-7p547w"><p style="color:var(--ifm-color-primary)">2019<!-- -->: <!-- -->Researcher<!-- --> at <!-- -->Frontier Development Lab</p><p>At <a target="_blank" rel="noopener noreferrer" href="https://fdleurope.org">Frontier Developemnt Lab</a>, we built a flood segmentation model. In the process, we collaborated with the European Space Agency and UNICEF. The model has now been deployed by SpaceX on an actual satellite üõ∞. Our work was covered by <a target="_blank" rel="noopener noreferrer" href="https://www.ox.ac.uk/news/2021-06-29-artificial-intelligence-pioneered-oxford-detect-floods-launches-space">this</a> post from the University of Oxford; and by several media outlets: <a target="_blank" rel="noopener noreferrer" href="https://watchers.news/2021/07/11/worldfloods-ai-pioneered-at-oxford-for-global-flood-mapping-launches-into-space/">1</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.innovationnewsnetwork.com/historic-breakthroughs-in-flood-mapping-from-space/24369/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=historic-breakthroughs-in-flood-mapping-from-space)">2</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.homelandsecuritynewswire.com/dr20210712-detecting-floods-from-space-using-artificial-intelligence">3</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.cas.cn/kj/202107/t20210722_4799503.shtml">4</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.kepuchina.cn/more/202107/t20210722_3010644.shtml">5</a>. Check out our <a target="_blank" rel="noopener noreferrer" href="/publications/#Mateo-Garcia2021">Nature (Scientific Reports) paper</a> and the <a target="_blank" rel="noopener noreferrer" href="https://www.nature.com/articles/s41598-021-86650-z">video of the rocket launch</a> üöÄ</p><p><iframe width="504" height="283" src="https://www.youtube.com/embed/sSiuW1HcGjA?si=1T89v4S5tO-OhIlL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"></iframe></p><p></p></div></li><li class="MuiTimelineItem-root MuiTimelineItem-positionRight MuiTimelineItem-missingOppositeContent css-1rcbby2"><div class="MuiTimelineSeparator-root css-11tgw8h"><span class="MuiTimelineDot-root MuiTimelineDot-filled MuiTimelineDot-filledGrey css-1mfc72q"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="laptop-code" class="svg-inline--fa fa-laptop-code fa-lg" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M64 96c0-35.3 28.7-64 64-64H512c35.3 0 64 28.7 64 64V352H512V96H128V352H64V96zM0 403.2C0 392.6 8.6 384 19.2 384H620.8c10.6 0 19.2 8.6 19.2 19.2c0 42.4-34.4 76.8-76.8 76.8H76.8C34.4 480 0 445.6 0 403.2zM281 209l-31 31 31 31c9.4 9.4 9.4 24.6 0 33.9s-24.6 9.4-33.9 0l-48-48c-9.4-9.4-9.4-24.6 0-33.9l48-48c9.4-9.4 24.6-9.4 33.9 0s9.4 24.6 0 33.9zM393 175l48 48c9.4 9.4 9.4 24.6 0 33.9l-48 48c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l31-31-31-31c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0z"></path></svg></span><span class="MuiTimelineConnector-root css-t0sc32"></span></div><div class="MuiTypography-root MuiTypography-body1 MuiTimelineContent-root MuiTimelineContent-positionRight css-7p547w"><p style="color:var(--ifm-color-primary)">2014 - 2017<!-- -->: <!-- -->Engineer<!-- --> at <!-- -->VisualDNA and TheySay</p><p></p><p>During this time, I was an engineer at two tech startups. First, a software engineer at VisualDNA, a data science and management platform, where I worked on data aggregation and reporting using Scala and the Scalding interface to Hadoop. After VisualDNA, I spent some time as a contractor. Next, I was an artificial intelligence engineer at TheySay, a startup providing text analytics services, where I used technologies such as Scala and MongoDB.</p><p>Both startups were acquired, see <a target="_blank" rel="noopener noreferrer" href="https://www.businessinsider.com/teddy-sagi-acquires-visualdna-2015-5?r=US&amp;IR=T">this article about VisualDNA</a>, and <a target="_blank" rel="noopener noreferrer" href="https://www.aptean.com/fr/insights/press-release/aptean-expands-text-analytics-capabilities-with-theysay-acquisition">this one about TheySay</a>.</p><p></p></div></li><li class="MuiTimelineItem-root MuiTimelineItem-positionRight MuiTimelineItem-missingOppositeContent css-1rcbby2"><div class="MuiTimelineSeparator-root css-11tgw8h"><span class="MuiTimelineDot-root MuiTimelineDot-filled MuiTimelineDot-filledGrey css-1mfc72q"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="laptop-code" class="svg-inline--fa fa-laptop-code fa-lg" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M64 96c0-35.3 28.7-64 64-64H512c35.3 0 64 28.7 64 64V352H512V96H128V352H64V96zM0 403.2C0 392.6 8.6 384 19.2 384H620.8c10.6 0 19.2 8.6 19.2 19.2c0 42.4-34.4 76.8-76.8 76.8H76.8C34.4 480 0 445.6 0 403.2zM281 209l-31 31 31 31c9.4 9.4 9.4 24.6 0 33.9s-24.6 9.4-33.9 0l-48-48c-9.4-9.4-9.4-24.6 0-33.9l48-48c9.4-9.4 24.6-9.4 33.9 0s9.4 24.6 0 33.9zM393 175l48 48c9.4 9.4 9.4 24.6 0 33.9l-48 48c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l31-31-31-31c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0z"></path></svg></span><span class="MuiTimelineConnector-root css-t0sc32"></span></div><div class="MuiTypography-root MuiTypography-body1 MuiTimelineContent-root MuiTimelineContent-positionRight css-7p547w"><p style="color:var(--ifm-color-primary)">2012<!-- -->: <!-- -->Guest Researcher<!-- --> at <!-- -->the National Institute for Standards and Technology</p><p>I worked with <a target="_blank" rel="noopener noreferrer" href="https://www.nist.gov/people/bruce-r-miller">Bruce Miller</a> on extending <a target="_blank" rel="noopener noreferrer" href="https://math.nist.gov/~BMiller/LaTeXML/">LaTeXML</a>, a <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/TeX">TeX</a> parser that he wrote in <a target="_blank" rel="noopener noreferrer" href="https://www.perl.org/">Perl</a>. The goal of my extenssion was to convert <a target="_blank" rel="noopener noreferrer" href="https://tikz.net/">TikZ</a> graphics to <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/SVG">SVG</a>. See <a target="_blank" rel="noopener noreferrer" href="https://link.springer.com/chapter/10.1007/978-3-319-08434-3_32">this paper</a> that mentions my work.</p></div></li></ul><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="teaching">Teaching<a href="#teaching" class="hash-link" aria-label="Direct link to Teaching" title="Direct link to Teaching">‚Äã</a></h2><ul><li>2021: <em>Lab demonstrator</em> for <em>Text Technologies in Data Science</em> at the <em>University of Edinburgh</em>.</li><li>2010 and 2011: <em>Teaching assistant</em> for <em>Programming in C/C++</em> at <em>Jacobs University Bremen</em>.</li></ul><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="media-coverage">Media coverage<a href="#media-coverage" class="hash-link" aria-label="Direct link to Media coverage" title="Direct link to Media coverage">‚Äã</a></h2><p>Our paper, <a href="https://www.nature.com/articles/s41598-021-86650-z" target="_blank" rel="noopener noreferrer">Towards global flood mapping onboard low cost satellites with machine learning</a>, published in Nature (Scientific Reports) in 2021, was covered by the following articles:</p><ul><li>University of Oxford: <a href="https://www.ox.ac.uk/news/2021-06-29-artificial-intelligence-pioneered-oxford-detect-floods-launches-space" target="_blank" rel="noopener noreferrer">Artificial Intelligence pioneered at Oxford to detect floods launches into space</a></li><li>The Watchers: <a href="https://watchers.news/2021/07/11/worldfloods-ai-pioneered-at-oxford-for-global-flood-mapping-launches-into-space/" target="_blank" rel="noopener noreferrer">WorldFloods ‚Äì AI pioneered at Oxford for global flood mapping launches into space</a></li><li>Innovation News Network: <a href="https://www.innovationnewsnetwork.com/historic-breakthroughs-in-flood-mapping-from-space/24369/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=historic-breakthroughs-in-flood-mapping-from-space" target="_blank" rel="noopener noreferrer">A look at historic breakthroughs in flood mapping from space</a></li><li>Homeland Security News Wire: <a href="https://www.homelandsecuritynewswire.com/dr20210712-detecting-floods-from-space-using-artificial-intelligence" target="_blank" rel="noopener noreferrer">Detecting Floods from Space Using Artificial Intelligence</a></li><li>Chinese Academy of Sciences: <a href="https://www.cas.cn/kj/202107/t20210722_4799503.shtml" target="_blank" rel="noopener noreferrer">AIÂä†ÊåÅÈÅ•ÊÑüÊäÄÊúØËÉΩÂê¶‰∏∫Èò≤Ê±õ&quot;Â§áÊñô&quot;</a></li><li>China Science Communication: <a href="https://www.kepuchina.cn/more/202107/t20210722_3010644.shtml" target="_blank" rel="noopener noreferrer">AIÂä†ÊåÅÔºåÈÅ•Áû∞Ê¥™Ê∂õ</a></li></ul><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="patents">Patents<a href="#patents" class="hash-link" aria-label="Direct link to Patents" title="Direct link to Patents">‚Äã</a></h2><h4>European patent office</h4><ul><li style="margin-bottom:.5rem"><div style="margin-bottom:1.5rem"><div>Processing communications in a computing arrangement for semantic understanding and interpretation of code-switching</div><div>Sourav Dutta<!-- -->, <u>Silviu Vlad Oprea</u>, <!-- -->Haytham Assem<!-- -->, and <!-- -->Hu Peng</div><div><i>Patent WO2022069030A1 issued from application PCT/EP2020/077336</i>. <!-- -->2022<!-- -->.</div><button class="tag">ABS</button><a class="tag" style="margin-left:.625rem" href="https://worldwide.espacenet.com/patent/search/family/072709373/publication/WO2022069030A1?q=WO2022069030A1&amp;queryLang=en%3Ade%3Afr" target="_blank" rel="noopener noreferrer">html</a><div class="abstract hidden">A method of processing a communication in a computing arrangement that increases accuracy of semantic understanding and improves meaningful interpretation of code- switched regions in the communication. The method includes using the computing arrangement to analyze the communication to identify a predominant language used in the communication, and also to identify one or more code switched regions occurring in the communication. The method further includes using an artificial intelligence (AI) engine of the computing arrangement to translate the one or more languages used in the respective one or more code switched regions into one or more equivalent expressions of the predominant language. The one or more code switched regions of the communication are then replacing or supplemented with the one or more equivalent expressions included into the communication.</div></div></li></ul><p>My Google Patents page is <a href="https://patents.google.com/?inventor=Silviu+Oprea&amp;oq=inventor:(Silviu+Oprea)" target="_blank" rel="noopener noreferrer">here</a>.</p><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="publications">Publications<a href="#publications" class="hash-link" aria-label="Direct link to Publications" title="Direct link to Publications">‚Äã</a></h2><h4>Figurative language comprehension</h4><ul><li style="margin-bottom:.5rem"><div style="margin-bottom:1.5rem"><div>Sarcasm Detection is Way Too Easy! An Empirical Comparison of Human and Machine Sarcasm Detection</div><div>Ibrahim Abu Farha<!-- -->, <!-- -->Steven Wilson<!-- -->, <u>Silviu Vlad Oprea</u>, and <!-- -->Walid Magdy</div><div><i>Findings of the Association for Computational Linguistics</i>. <!-- -->2022<!-- -->.</div><button class="tag">ABS</button><button class="tag" style="margin-left:.625rem">BIB</button><a class="tag" style="margin-left:.625rem" href="https://aclanthology.org/2022.findings-emnlp.387.pdf" target="_blank" rel="noopener noreferrer">pdf</a><div class="abstract hidden">Recently, author-annotated sarcasm datasets, which focus on intended, rather than perceived sarcasm, have been introduced. Although datasets collected using first-party annotation have important benefits, there is no comparison of human and machine performance on these new datasets. In this paper, we collect new annotations to provide human-level benchmarks for these first-party annotated sarcasm tasks in both English and Arabic, and compare the performance of human annotators to that of state-of-the-art sarcasm detection systems. Our analysis confirms that sarcasm detection is extremely challenging, with individual humans performing close to or slightly worse than the best trained models. With majority voting, however, humans are able to achieve the best results on all tasks. We also perform error analysis, finding that some of the most challenging examples are those that require additional context. We also highlight common features and patterns used to express sarcasm in English and Arabic such as idioms and proverbs. We suggest that to better capture sarcasm, future sarcasm detection datasets and models should focus on representing conversational and cultural context while leveraging world knowledge and common sense.</div><div class="bibtex hidden"><div class="language-latex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-latex codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@inproceedings{abu-farha-etal-2022-sarcasm,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    title = {Sarcasm Detection is Way Too Easy! An Empirical Comparison of Human and Machine Sarcasm Detection},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    author = {Abu Farha, Ibrahim and Wilson, Steven and Oprea, Silviu Vlad and Magdy, Walid},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2022},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    month = dec,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    year = {2022},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    address = {Abu Dhabi, United Arab Emirates},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    publisher = {Association for Computational Linguistics},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    url = {https://aclanthology.org/2022.findings-emnlp.387},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    doi = {10.18653/v1/2022.findings-emnlp.387},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pages = {5284--5295},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></li><li style="margin-bottom:.5rem"><div style="margin-bottom:1.5rem"><div>SemEval-2022 Task 6: iSarcasmEval, Intended Sarcasm Detection in English and Arabic</div><div>Ibrahim Abu Farha<!-- -->, <u>Silviu Vlad Oprea</u>, <!-- -->Steven Wilson<!-- -->, and <!-- -->Walid Magdy</div><div><i>Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022)</i>. <!-- -->2022<!-- -->.</div><button class="tag">ABS</button><button class="tag" style="margin-left:.625rem">BIB</button><a class="tag" style="margin-left:.625rem" href="https://aclanthology.org/2022.semeval-1.111.pdf" target="_blank" rel="noopener noreferrer">pdf</a><a class="tag" style="margin-left:.625rem" href="https://aclanthology.org/2022.semeval-1.111.mp4" target="_blank" rel="noopener noreferrer">video</a><div class="abstract hidden">iSarcasmEval is the first shared task to target intended sarcasm detection: the data for this task was provided and labelled by the authors of the texts themselves. Such an approach minimises the downfalls of other methods to collect sarcasm data, which rely on distant supervision or third-party annotations. The shared task contains two languages, English and Arabic, and three subtasks: sarcasm detection, sarcasm category classification, and pairwise sarcasm identification given a sarcastic sentence and its non-sarcastic rephrase. The task received submissions from 60 different teams, with the sarcasm detection task being the most popular. Most of the participating teams utilised pre-trained language models. In this paper, we provide an overview of the task, data, and participating teams.</div><div class="bibtex hidden"><div class="language-latex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-latex codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@inproceedings{abu-farha-etal-2022-semeval,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    title = {{S}em{E}val-2022 Task 6: i{S}arcasm{E}val, Intended Sarcasm Detection in {E}nglish and {A}rabic},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    author = {Abu Farha, Ibrahim and Oprea, Silviu Vlad and Wilson, Steven and Magdy, Walid},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    booktitle = {Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022)},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    month = jul,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    year = {2022},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    address = {Seattle, United States},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    publisher = {Association for Computational Linguistics},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    url = {https://aclanthology.org/2022.semeval-1.111},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    doi = {10.18653/v1/2022.semeval-1.111},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pages = {802--814},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></li><li style="margin-bottom:.5rem"><div style="margin-bottom:1.5rem"><div>iSarcasm: A Dataset of Intended Sarcasm</div><div><u>Silviu Vlad Oprea</u>, and <!-- -->Walid Magdy</div><div><i>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</i>. <!-- -->2020<!-- -->.</div><button class="tag">ABS</button><button class="tag" style="margin-left:.625rem">BIB</button><a class="tag" style="margin-left:.625rem" href="https://aclanthology.org/2020.acl-main.118.pdf" target="_blank" rel="noopener noreferrer">pdf</a><a class="tag" style="margin-left:.625rem" href="http://slideslive.com/38929208" target="_blank" rel="noopener noreferrer">video</a><div class="abstract hidden">Online social networks (OSN) play an essential role for connecting people and allowing them to communicate online. OSN users share their thoughts, moments, and news with their network. The messages they share online can include sarcastic posts, where the intended meaning expressed by the written text is different from the literal one. This could result in miscommunication. Previous research in psycholinguistics has studied the sociocultural factors the might lead to sarcasm misunderstanding between speakers and listeners. However, there is a lack of such studies in the context of OSN. In this paper we fill this gap by performing a quantitative analysis on the influence of sociocultural variables, including gender, age, country, and English language nativeness, on the effectiveness of sarcastic communication online. We collect examples of sarcastic tweets directly from the authors who posted them. Further, we ask third-party annotators of different sociocultural backgrounds to label these tweets for sarcasm. Our analysis indicates that age, English language nativeness, and country are significantly influential and should be considered in the design of future social analysis tools that either study sarcasm directly, or look at related phenomena where sarcasm may have an influence. We also make observations about the social ecology surrounding sarcastic exchanges on OSNs. We conclude by suggesting ways in which our findings can be included in future work.</div><div class="bibtex hidden"><div class="language-latex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-latex codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@inproceedings{oprea-magdy-2020-isarcasm,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    title = {i{S}arcasm: A Dataset of Intended Sarcasm},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    author = {Oprea, Silviu Vlad and Magdy, Walid},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    month = jul,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    year = {2020},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    address = {Online},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    publisher = {Association for Computational Linguistics},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    url = {https://aclanthology.org/2020.acl-main.118},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    doi = {10.18653/v1/2020.acl-main.118},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pages = {1279--1289},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></li><li style="margin-bottom:.5rem"><div style="margin-bottom:1.5rem"><div>Exploring Author Context for Detecting Intended vs Perceived Sarcasm</div><div><u>Silviu Vlad Oprea</u>, and <!-- -->Walid Magdy</div><div><i>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</i>. <!-- -->2019<!-- -->.</div><button class="tag">ABS</button><button class="tag" style="margin-left:.625rem">BIB</button><a class="tag" style="margin-left:.625rem" href="https://aclanthology.org/P19-1275.pdf" target="_blank" rel="noopener noreferrer">pdf</a><a class="tag" style="margin-left:.625rem" href="https://vimeo.com/384744638" target="_blank" rel="noopener noreferrer">video</a><div class="abstract hidden">We investigate the impact of using author context on textual sarcasm detection. We define author context as the embedded representation of their historical posts on Twitter and suggest neural models that extract these representations. We experiment with two tweet datasets, one labelled manually for sarcasm, and the other via tag-based distant supervision. We achieve state-of-the-art performance on the second dataset, but not on the one labelled manually, indicating a difference between intended sarcasm, captured by distant supervision, and perceived sarcasm, captured by manual labelling.</div><div class="bibtex hidden"><div class="language-latex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-latex codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@inproceedings{oprea-magdy-2019-exploring,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    title = {Exploring Author Context for Detecting Intended vs Perceived Sarcasm},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    author = {Oprea, Silviu Vlad and Magdy, Walid},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    month = jul,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    year = {2019},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    address = {Florence, Italy},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    publisher = {Association for Computational Linguistics},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    url = {https://aclanthology.org/P19-1275},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    doi = {10.18653/v1/P19-1275},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pages = {2854--2859},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></li></ul><h4>Computational social science</h4><ul><li style="margin-bottom:.5rem"><div style="margin-bottom:1.5rem"><div>Should a Chatbot be Sarcastic? Understanding User Preferences Towards Sarcasm Generation</div><div><u>Silviu Vlad Oprea</u>, <!-- -->Steven Wilson<!-- -->, and <!-- -->Walid Magdy</div><div><i>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</i>. <!-- -->2022<!-- -->.</div><button class="tag">ABS</button><button class="tag" style="margin-left:.625rem">BIB</button><a class="tag" style="margin-left:.625rem" href="https://aclanthology.org/2022.acl-long.530.pdf" target="_blank" rel="noopener noreferrer">pdf</a><a class="tag" style="margin-left:.625rem" href="https://aclanthology.org/2022.acl-long.530.mp4" target="_blank" rel="noopener noreferrer">video</a><div class="abstract hidden">Previous sarcasm generation research has focused on how to generate text that people perceive as sarcastic to create more human-like interactions. In this paper, we argue that we should first turn our attention to the question of when sarcasm should be generated, finding that humans consider sarcastic responses inappropriate to many input utterances. Next, we use a theory-driven framework for generating sarcastic responses, which allows us to control the linguistic devices included during generation. For each device, we investigate how much humans associate it with sarcasm, finding that pragmatic insincerity and emotional markers are devices crucial for making sarcasm recognisable.</div><div class="bibtex hidden"><div class="language-latex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-latex codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@inproceedings{oprea-etal-2022-chatbot,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    title = {Should a Chatbot be Sarcastic? Understanding User Preferences Towards Sarcasm Generation},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    author = {Oprea, Silviu Vlad and Wilson, Steven and Magdy, Walid},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    month = may,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    year = {2022},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    address = {Dublin, Ireland},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    publisher = {Association for Computational Linguistics},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    url = {https://aclanthology.org/2022.acl-long.530},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    doi = {10.18653/v1/2022.acl-long.530},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pages = {7686--7700},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></li><li style="margin-bottom:.5rem"><div style="margin-bottom:1.5rem"><div>The Effect of Sociocultural Variables on Sarcasm Communication Online</div><div><u>Silviu Vlad Oprea</u>, and <!-- -->Walid Magdy</div><div><i>Proceedings of the ACM on Human-Computer Interaction</i>. <!-- -->2020<!-- -->.</div><button class="tag">ABS</button><button class="tag" style="margin-left:.625rem">BIB</button><a class="tag" style="margin-left:.625rem" href="https://arxiv.org/pdf/2004.04945.pdf" target="_blank" rel="noopener noreferrer">pdf</a><a class="tag" style="margin-left:.625rem" href="https://dl.acm.org/doi/abs/10.1145/3392834" target="_blank" rel="noopener noreferrer">html</a><div class="abstract hidden">Online social networks (OSN) play an essential role for connecting people and allowing them to communicate online. OSN users share their thoughts, moments, and news with their network. The messages they share online can include sarcastic posts, where the intended meaning expressed by the written text is different from the literal one. This could result in miscommunication. Previous research in psycholinguistics has studied the sociocultural factors the might lead to sarcasm misunderstanding between speakers and listeners. However, there is a lack of such studies in the context of OSN. In this paper we fill this gap by performing a quantitative analysis on the influence of sociocultural variables, including gender, age, country, and English language nativeness, on the effectiveness of sarcastic communication online. We collect examples of sarcastic tweets directly from the authors who posted them. Further, we ask third-party annotators of different sociocultural backgrounds to label these tweets for sarcasm. Our analysis indicates that age, English language nativeness, and country are significantly influential and should be considered in the design of future social analysis tools that either study sarcasm directly, or look at related phenomena where sarcasm may have an influence. We also make observations about the social ecology surrounding sarcastic exchanges on OSNs. We conclude by suggesting ways in which our findings can be included in future work.</div><div class="bibtex hidden"><div class="language-latex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-latex codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@article{oprea-magdy-2020-the-effect,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    author = {Oprea, Silviu Vlad and Magdy, Walid},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    title = {The Effect of Sociocultural Variables on Sarcasm Communication Online},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    year = {2020},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    issue_date = {May 2020},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    publisher = {Association for Computing Machinery},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    address = {New York, NY, USA},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    volume = {4},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    number = {CSCW1},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    url = {https://doi.org/10.1145/3392834},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    doi = {10.1145/3392834},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    journal = {Proceedings of the ACM on Human-Computer Interaction},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    month = may,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    articleno = {29},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    numpages = {22},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    keywords = {online communication, sarcasm, social media, sociocultural background},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></li></ul><h4>Controllable text generation</h4><ul><li style="margin-bottom:.5rem"><div style="margin-bottom:1.5rem"><div>Chandler: An Explainable Sarcastic Response Generator</div><div><u>Silviu Vlad Oprea</u>, <!-- -->Steven Wilson<!-- -->, and <!-- -->Walid Magdy</div><div><i>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</i>. <!-- -->2021<!-- -->.</div><button class="tag">ABS</button><button class="tag" style="margin-left:.625rem">BIB</button><a class="tag" style="margin-left:.625rem" href="https://aclanthology.org/2021.emnlp-demo.38.pdf" target="_blank" rel="noopener noreferrer">pdf</a><a class="tag" style="margin-left:.625rem" href="https://aclanthology.org/2021.emnlp-demo.38.mp4" target="_blank" rel="noopener noreferrer">video</a><div class="abstract hidden">We introduce Chandler, a system that generates sarcastic responses to a given utterance. Previous sarcasm generators assume the intended meaning that sarcasm conceals is the opposite of the literal meaning. We argue that this traditional theory of sarcasm provides a grounding that is neither necessary, nor sufficient, for sarcasm to occur. Instead, we ground our generation process on a formal theory that specifies conditions that unambiguously differentiate sarcasm from non-sarcasm. Furthermore, Chandler not only generates sarcastic responses, but also explanations for why each response is sarcastic. This provides accountability, crucial for avoiding miscommunication between humans and conversational agents, particularly considering that sarcastic communication can be offensive. In human evaluation, Chandler achieves comparable or higher sarcasm scores, compared to state-of-the-art generators, while generating more diverse responses, that are more specific and more coherent to the input.</div><div class="bibtex hidden"><div class="language-latex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-latex codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@inproceedings{oprea-etal-2021-chandler,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    title = {Chandler: An Explainable Sarcastic Response Generator},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    author = {Oprea, Silviu Vlad and Wilson, Steven and Magdy, Walid},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    month = nov,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    year = {2021},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    address = {Online and Punta Cana, Dominican Republic},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    publisher = {Association for Computational Linguistics},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    url = {https://aclanthology.org/2021.emnlp-demo.38},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    doi = {10.18653/v1/2021.emnlp-demo.38},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pages = {339--349},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></li></ul><h4>Machine translation</h4><ul><li style="margin-bottom:.5rem"><div style="margin-bottom:1.5rem"><div>Multi-Stage Framework with Refinement Based Point Set Registration for Unsupervised Bi-Lingual Word Alignment</div><div><u>Silviu Vlad Oprea</u>, <!-- -->Sourav Dutta<!-- -->, and <!-- -->Haytham Assem</div><div><i>Proceedings of the 29th International Conference on Computational Linguistics</i>. <!-- -->2022<!-- -->.</div><button class="tag">ABS</button><button class="tag" style="margin-left:.625rem">BIB</button><a class="tag" style="margin-left:.625rem" href="https://aclanthology.org/2022.coling-1.92.pdf" target="_blank" rel="noopener noreferrer">pdf</a><div class="abstract hidden">Cross-lingual alignment of word embeddings are important in knowledge transfer across languages, for improving machine translation and other multi-lingual applications. Current unsupervised approaches relying on learning structure-preserving transformations, using adversarial networks and refinement strategies, suffer from instability and convergence issues. This paper proposes BioSpere, a novel multi-stage framework for unsupervised mapping of bi-lingual word embeddings onto a shared vector space, by combining adversarial initialization, refinement procedure and point set registration. Experiments for parallel dictionary induction and word similarity demonstrate state-of-the-art unsupervised results for BioSpere on diverse languages ‚Äì showcasing robustness against variable adversarial performance.</div><div class="bibtex hidden"><div class="language-latex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-latex codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@inproceedings{oprea-etal-2022-multi,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    title = {Multi-Stage Framework with Refinement Based Point Set Registration for Unsupervised Bi-Lingual Word Alignment},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    author = {Oprea, Silviu Vlad and Dutta, Sourav and Assem, Haytham},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    booktitle = {Proceedings of the 29th International Conference on Computational Linguistics},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    month = oct,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    year = {2022},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    address = {Gyeongju, Republic of Korea},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    publisher = {International Committee on Computational Linguistics},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    url = {https://aclanthology.org/2022.coling-1.92},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pages = {1089--1097},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></li></ul><h4>Computer vision</h4><ul><li style="margin-bottom:.5rem"><div style="margin-bottom:1.5rem"><div>Towards global flood mapping onboard low cost satellites with machine learning</div><div>Gonzalo Mateo-Garcia*<!-- -->, <!-- -->Joshua Veitch-Michaelis*<!-- -->, <!-- -->Lewis Smith*<!-- -->, <u>Silviu Vlad Oprea</u>, <!-- -->Guy Schumann<!-- -->, <!-- -->Yarin Gal<!-- -->, <!-- -->Atƒ±lƒ±m G√ºne≈ü Baydin<!-- -->, and <!-- -->Dietmar Backes</div><div><i>Nature (Scientific Reports)</i>. <!-- -->2021<!-- -->.</div><button class="tag">ABS</button><button class="tag" style="margin-left:.625rem">BIB</button><a class="tag" style="margin-left:.625rem" href="https://www.nature.com/articles/s41598-021-86650-z" target="_blank" rel="noopener noreferrer">html</a><div class="abstract hidden">Spaceborne Earth observation is a key technology for flood response, offering valuable information to decision makers on the ground. Very large constellations of small, nano satellites‚Äî ‚ÄôCubeSats‚Äô are a promising solution to reduce revisit time in disaster areas from days to hours. However, data transmission to ground receivers is limited by constraints on power and bandwidth of CubeSats. Onboard processing offers a solution to decrease the amount of data to transmit by reducing large sensor images to smaller data products. The ESA‚Äôs recent PhiSat-1 mission aims to facilitate the demonstration of this concept, providing the hardware capability to perform onboard processing by including a power-constrained machine learning accelerator and the software to run custom applications. This work demonstrates a flood segmentation algorithm that produces flood masks to be transmitted instead of the raw images, while running efficiently on the accelerator aboard the PhiSat-1. Our models are trained on WorldFloods: a newly compiled dataset of 119 globally verified flooding events from disaster response organizations, which we make available in a common format. We test the system on independent locations, demonstrating that it produces fast and accurate segmentation masks on the hardware accelerator, acting as a proof of concept for this approach.</div><div class="bibtex hidden"><div class="language-latex codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-latex codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@article{Mateo-Garcia2021,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    author = {Mateo-Garcia, Gonzalo and Veitch-Michaelis, Joshua and Smith, Lewis and Oprea, Silviu Vlad and Schumann, Guy and Gal, Yarin and Baydin, At{i}l{i}m G{&quot;u}ne{c{s}} and Backes, Dietmar},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    title = {Towards global flood mapping onboard low cost satellites with machine learning},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    journal = {Scientific Reports},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    year = {2021},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    month = mar,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    day = {31},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    volume = {11},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    number = {1},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pages = {7249},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    issn = {2045-2322},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    doi = {10.1038/s41598-021-86650-z},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    url = {https://doi.org/10.1038/s41598-021-86650-z},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></li></ul><p>*<!-- --> indicates equal contribution. Check the full list of publications on <a href="https://scholar.google.com/citations?user=IOVYUDwAAAAJ" target="_blank" rel="noopener noreferrer">my Google Scholar profile</a>.</p></article></div><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#news" class="table-of-contents__link toc-highlight">News</a></li><li><a href="#education" class="table-of-contents__link toc-highlight">Education</a></li><li><a href="#work" class="table-of-contents__link toc-highlight">Work</a></li><li><a href="#teaching" class="table-of-contents__link toc-highlight">Teaching</a></li><li><a href="#media-coverage" class="table-of-contents__link toc-highlight">Media coverage</a></li><li><a href="#patents" class="table-of-contents__link toc-highlight">Patents</a></li><li><a href="#publications" class="table-of-contents__link toc-highlight">Publications</a></li></ul></div></div></div></main></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2023 Silviu Vlad Oprea. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.cf15a1a1.js"></script>
<script src="/assets/js/main.2b128fc2.js"></script>
</body>
</html>